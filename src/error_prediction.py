#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯¯å·®é¢„æµ‹æ¨¡å‹
ä½¿ç”¨KDEå¯†åº¦ä½œä¸ºç‰¹å¾ï¼Œé¢„æµ‹MAEè¯¯å·®
"""

import numpy as np
import pandas as pd
from sklearn.linear_model import Ridge, RidgeCV
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import pickle
import os
from typing import Tuple, Dict, Optional, List
import warnings
warnings.filterwarnings('ignore')

class ErrorPredictor:
    """åŸºäºKDEå¯†åº¦çš„è¯¯å·®é¢„æµ‹å™¨"""
    
    def __init__(self, alpha: float = 1.0):
        self.alpha = alpha
        self.model = Ridge(alpha=alpha, random_state=42)
        self.scaler = StandardScaler()
        self.fitted = False
        self.feature_names = ['kde_density']
        
    def prepare_features(self, kde_densities: np.ndarray) -> np.ndarray:
        """
        å‡†å¤‡ç‰¹å¾çŸ©é˜µ
        
        Args:
            kde_densities: KDEå¯†åº¦å€¼
            
        Returns:
            ç‰¹å¾çŸ©é˜µ
        """
        # åŸºç¡€ç‰¹å¾ï¼šåŸå§‹KDEå¯†åº¦
        features = kde_densities.reshape(-1, 1)
        
        # æ‰©å±•ç‰¹å¾ï¼šå¢åŠ éçº¿æ€§å˜æ¢
        kde_log = np.log(kde_densities + 1e-10).reshape(-1, 1)  # å¯¹æ•°å˜æ¢
        kde_sqrt = np.sqrt(kde_densities).reshape(-1, 1)  # å¹³æ–¹æ ¹å˜æ¢
        kde_square = (kde_densities ** 2).reshape(-1, 1)  # å¹³æ–¹å˜æ¢
        kde_inv = (1 / (kde_densities + 1e-10)).reshape(-1, 1)  # å€’æ•°å˜æ¢
        
        # ç»„åˆç‰¹å¾
        features_extended = np.hstack([
            features,      # åŸå§‹å¯†åº¦
            kde_log,       # å¯¹æ•°å¯†åº¦
            kde_sqrt,      # å¹³æ–¹æ ¹å¯†åº¦
            kde_square,    # å¹³æ–¹å¯†åº¦
            kde_inv        # å€’æ•°å¯†åº¦
        ])
        
        self.feature_names = [
            'kde_density', 'kde_log', 'kde_sqrt', 'kde_square', 'kde_inv'
        ]
        
        return features_extended
    
    def fit(self, kde_densities: np.ndarray, mae_values: np.ndarray, 
            test_size: float = 0.2) -> Dict:
        """
        è®­ç»ƒè¯¯å·®é¢„æµ‹æ¨¡å‹
        
        Args:
            kde_densities: KDEå¯†åº¦å€¼
            mae_values: MAEå€¼ 
            test_size: æµ‹è¯•é›†æ¯”ä¾‹
            
        Returns:
            è®­ç»ƒç»“æœå­—å…¸
        """
        print("ğŸ‹ï¸ å¼€å§‹è®­ç»ƒè¯¯å·®é¢„æµ‹æ¨¡å‹...")
        
        # å‡†å¤‡ç‰¹å¾
        X = self.prepare_features(kde_densities)
        y = mae_values
        
        print(f"   ç‰¹å¾ç»´åº¦: {X.shape}")
        print(f"   ç›®æ ‡å˜é‡èŒƒå›´: {y.min():.2f} - {y.max():.2f}")
        
        # æ•°æ®åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # è®­ç»ƒæ¨¡å‹
        self.model.fit(X_train_scaled, y_train)
        self.fitted = True
        
        # é¢„æµ‹
        y_train_pred = self.model.predict(X_train_scaled)
        y_test_pred = self.model.predict(X_test_scaled)
        
        # è®¡ç®—æŒ‡æ ‡
        train_mae = mean_absolute_error(y_train, y_train_pred)
        test_mae = mean_absolute_error(y_test, y_test_pred)
        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
        train_r2 = r2_score(y_train, y_train_pred)
        test_r2 = r2_score(y_test, y_test_pred)
        
        # äº¤å‰éªŒè¯
        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, 
                                   cv=5, scoring='neg_mean_absolute_error')
        cv_mae = -cv_scores.mean()
        cv_std = cv_scores.std()
        
        results = {
            'train_mae': train_mae,
            'test_mae': test_mae,
            'train_rmse': train_rmse,
            'test_rmse': test_rmse,
            'train_r2': train_r2,
            'test_r2': test_r2,
            'cv_mae': cv_mae,
            'cv_std': cv_std,
            'model_coefficients': self.model.coef_,
            'model_intercept': self.model.intercept_,
            'feature_names': self.feature_names,
            'alpha': self.alpha,
            'train_predictions': y_train_pred,
            'test_predictions': y_test_pred,
            'y_train': y_train,
            'y_test': y_test,
            'X_train': X_train,
            'X_test': X_test
        }
        
        print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ:")
        print(f"   è®­ç»ƒé›† MAE: {train_mae:.3f}, RÂ²: {train_r2:.3f}")
        print(f"   æµ‹è¯•é›† MAE: {test_mae:.3f}, RÂ²: {test_r2:.3f}")
        print(f"   äº¤å‰éªŒè¯ MAE: {cv_mae:.3f} Â± {cv_std:.3f}")
        
        return results
    
    def optimize_hyperparameters(self, kde_densities: np.ndarray, mae_values: np.ndarray) -> float:
        """ä¼˜åŒ–è¶…å‚æ•°"""
        print("ğŸ”§ ä¼˜åŒ–Ridgeå›å½’è¶…å‚æ•°...")
        
        # å‡†å¤‡ç‰¹å¾
        X = self.prepare_features(kde_densities)
        y = mae_values
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X)
        
        # è¶…å‚æ•°æœç´¢èŒƒå›´
        alphas = np.logspace(-3, 2, 50)  # 0.001 to 100
        
        # ä½¿ç”¨RidgeCVè¿›è¡Œäº¤å‰éªŒè¯
        ridge_cv = RidgeCV(alphas=alphas, cv=5, scoring='neg_mean_absolute_error')
        ridge_cv.fit(X_scaled, y)
        
        best_alpha = ridge_cv.alpha_
        self.alpha = best_alpha
        self.model = Ridge(alpha=best_alpha, random_state=42)
        
        print(f"âœ… æœ€ä¼˜è¶…å‚æ•°: alpha = {best_alpha:.4f}")
        
        return best_alpha
    
    def predict(self, kde_densities: np.ndarray) -> np.ndarray:
        """é¢„æµ‹MAEå€¼"""
        if not self.fitted:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fit()æ–¹æ³•")
        
        X = self.prepare_features(kde_densities)
        X_scaled = self.scaler.transform(X)
        predictions = self.model.predict(X_scaled)
        
        return predictions
    
    def get_feature_importance(self) -> Dict:
        """è·å–ç‰¹å¾é‡è¦æ€§"""
        if not self.fitted:
            return {}
        
        importance_dict = {}
        for i, name in enumerate(self.feature_names):
            importance_dict[name] = abs(self.model.coef_[i])
        
        # æŒ‰é‡è¦æ€§æ’åº
        sorted_importance = dict(sorted(importance_dict.items(), 
                                      key=lambda x: x[1], reverse=True))
        
        return sorted_importance
    
    def save_model(self, save_path: str):
        """ä¿å­˜æ¨¡å‹"""
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'alpha': self.alpha,
            'feature_names': self.feature_names,
            'fitted': self.fitted
        }
        
        with open(save_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
    
    def load_model(self, save_path: str):
        """åŠ è½½æ¨¡å‹"""
        with open(save_path, 'rb') as f:
            model_data = pickle.load(f)
        
        self.model = model_data['model']
        self.scaler = model_data['scaler']
        self.alpha = model_data['alpha']
        self.feature_names = model_data['feature_names']
        self.fitted = model_data['fitted']
        
        print(f"ğŸ“ æ¨¡å‹å·²ä» {save_path} åŠ è½½")

def plot_prediction_results(results: Dict, save_path: Optional[str] = None):
    """ç»˜åˆ¶é¢„æµ‹ç»“æœ"""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('è¯¯å·®é¢„æµ‹æ¨¡å‹ç»“æœ', fontsize=16, fontweight='bold')
    
    # è®­ç»ƒé›†é¢„æµ‹vsçœŸå®
    axes[0, 0].scatter(results['y_train'], results['train_predictions'], alpha=0.6, s=2)
    min_val = min(results['y_train'].min(), results['train_predictions'].min())
    max_val = max(results['y_train'].max(), results['train_predictions'].max())
    axes[0, 0].plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)
    axes[0, 0].set_xlabel('çœŸå®MAE')
    axes[0, 0].set_ylabel('é¢„æµ‹MAE')
    axes[0, 0].set_title(f'è®­ç»ƒé›† (RÂ²={results["train_r2"]:.3f})')
    axes[0, 0].grid(True, alpha=0.3)
    
    # æµ‹è¯•é›†é¢„æµ‹vsçœŸå®
    axes[0, 1].scatter(results['y_test'], results['test_predictions'], alpha=0.6, s=2)
    min_val = min(results['y_test'].min(), results['test_predictions'].min())
    max_val = max(results['y_test'].max(), results['test_predictions'].max())
    axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)
    axes[0, 1].set_xlabel('çœŸå®MAE')
    axes[0, 1].set_ylabel('é¢„æµ‹MAE')
    axes[0, 1].set_title(f'æµ‹è¯•é›† (RÂ²={results["test_r2"]:.3f})')
    axes[0, 1].grid(True, alpha=0.3)
    
    # æ®‹å·®åˆ†æ
    train_residuals = results['y_train'] - results['train_predictions']
    test_residuals = results['y_test'] - results['test_predictions']
    
    axes[0, 2].scatter(results['train_predictions'], train_residuals, alpha=0.5, s=1, label='è®­ç»ƒé›†')
    axes[0, 2].scatter(results['test_predictions'], test_residuals, alpha=0.5, s=1, label='æµ‹è¯•é›†')
    axes[0, 2].axhline(y=0, color='r', linestyle='--', alpha=0.8)
    axes[0, 2].set_xlabel('é¢„æµ‹MAE')
    axes[0, 2].set_ylabel('æ®‹å·®')
    axes[0, 2].set_title('æ®‹å·®åˆ†æ')
    axes[0, 2].legend()
    axes[0, 2].grid(True, alpha=0.3)
    
    # æ¨¡å‹ç³»æ•°
    if 'model_coefficients' in results and 'feature_names' in results:
        coefs = results['model_coefficients']
        feature_names = results['feature_names']
        
        bars = axes[1, 0].barh(feature_names, coefs)
        axes[1, 0].set_xlabel('ç³»æ•°å€¼')
        axes[1, 0].set_title('æ¨¡å‹ç‰¹å¾ç³»æ•°')
        axes[1, 0].grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, coef in zip(bars, coefs):
            axes[1, 0].text(coef + 0.01 if coef >= 0 else coef - 0.01, 
                           bar.get_y() + bar.get_height()/2,
                           f'{coef:.3f}', ha='left' if coef >= 0 else 'right', va='center')
    
    # è¯¯å·®åˆ†å¸ƒå¯¹æ¯”
    axes[1, 1].hist(train_residuals, bins=30, alpha=0.5, label='è®­ç»ƒé›†æ®‹å·®', density=True)
    axes[1, 1].hist(test_residuals, bins=30, alpha=0.5, label='æµ‹è¯•é›†æ®‹å·®', density=True)
    axes[1, 1].set_xlabel('æ®‹å·®å€¼')
    axes[1, 1].set_ylabel('å¯†åº¦')
    axes[1, 1].set_title('æ®‹å·®åˆ†å¸ƒ')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    # æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”
    metrics_names = ['MAE', 'RMSE', 'RÂ²']
    train_metrics = [results['train_mae'], results['train_rmse'], results['train_r2']]
    test_metrics = [results['test_mae'], results['test_rmse'], results['test_r2']]
    
    x = np.arange(len(metrics_names))
    width = 0.35
    
    axes[1, 2].bar(x - width/2, train_metrics, width, label='è®­ç»ƒé›†', alpha=0.7)
    axes[1, 2].bar(x + width/2, test_metrics, width, label='æµ‹è¯•é›†', alpha=0.7)
    axes[1, 2].set_xlabel('æŒ‡æ ‡')
    axes[1, 2].set_ylabel('å€¼')
    axes[1, 2].set_title('æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”')
    axes[1, 2].set_xticks(x)
    axes[1, 2].set_xticklabels(metrics_names)
    axes[1, 2].legend()
    axes[1, 2].grid(True, alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (train_val, test_val) in enumerate(zip(train_metrics, test_metrics)):
        axes[1, 2].text(i - width/2, train_val + 0.01, f'{train_val:.3f}', 
                       ha='center', va='bottom', fontsize=8)
        axes[1, 2].text(i + width/2, test_val + 0.01, f'{test_val:.3f}', 
                       ha='center', va='bottom', fontsize=8)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š é¢„æµ‹ç»“æœå›¾å·²ä¿å­˜åˆ°: {save_path}")
    
    plt.show()

def run_error_prediction(kde_densities: np.ndarray, mae_values: np.ndarray) -> Dict:
    """
    è¿è¡Œå®Œæ•´çš„è¯¯å·®é¢„æµ‹æµç¨‹
    
    Args:
        kde_densities: KDEå¯†åº¦å€¼
        mae_values: MAEå€¼
        
    Returns:
        é¢„æµ‹ç»“æœå­—å…¸
    """
    print(f"ğŸš€ å¼€å§‹ä»»åŠ¡7ï¼šè¯¯å·®é¢„æµ‹æ¨¡å‹")
    print(f"   æ ·æœ¬æ•°é‡: {len(kde_densities)}")
    
    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = ErrorPredictor()
    
    # ä¼˜åŒ–è¶…å‚æ•°
    best_alpha = predictor.optimize_hyperparameters(kde_densities, mae_values)
    
    # è®­ç»ƒæ¨¡å‹
    results = predictor.fit(kde_densities, mae_values)
    
    # ç»˜åˆ¶ç»“æœ
    plot_prediction_results(results, 'results/plots/error_prediction_results.png')
    
    # è·å–ç‰¹å¾é‡è¦æ€§
    feature_importance = predictor.get_feature_importance()
    print(f"âœ… ç‰¹å¾é‡è¦æ€§:")
    for feature, importance in feature_importance.items():
        print(f"   {feature}: {importance:.4f}")
    
    # ä¿å­˜æ¨¡å‹
    os.makedirs('models', exist_ok=True)
    predictor.save_model('models/error_predictor.pkl')
    
    # ä¿å­˜ç»“æœ
    prediction_results = {
        'kde_density': kde_densities,
        'true_mae': mae_values,
        'predicted_mae_train': results['train_predictions'] if len(results['train_predictions']) > 0 else [],
        'predicted_mae_test': results['test_predictions'] if len(results['test_predictions']) > 0 else []
    }
    
    # ä¸ºæ‰€æœ‰æ•°æ®é¢„æµ‹
    all_predictions = predictor.predict(kde_densities)
    prediction_results['predicted_mae_all'] = all_predictions
    
    results_df = pd.DataFrame(prediction_results)
    results_df.to_csv('results/error_prediction_results.csv', index=False)
    
    # ç”Ÿæˆæ¨¡å‹æŠ¥å‘Š
    report = generate_prediction_report(results, feature_importance)
    with open('results/error_prediction_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… ä»»åŠ¡7å®Œæˆï¼")
    print(f"   æµ‹è¯•é›†RÂ²: {results['test_r2']:.3f}")
    print(f"   æµ‹è¯•é›†MAE: {results['test_mae']:.3f}")
    print(f"   æœ€ä¼˜æ­£åˆ™åŒ–å‚æ•°: {best_alpha:.4f}")
    print(f"   ç»“æœå·²ä¿å­˜åˆ°: results/")
    
    return results

def generate_prediction_report(results: Dict, feature_importance: Dict) -> str:
    """ç”Ÿæˆé¢„æµ‹æ¨¡å‹æŠ¥å‘Š"""
    
    # åˆ¤æ–­æ¨¡å‹æ€§èƒ½
    test_r2 = results['test_r2']
    if test_r2 > 0.5:
        performance = "ä¼˜ç§€"
    elif test_r2 > 0.3:
        performance = "è‰¯å¥½"
    elif test_r2 > 0.1:
        performance = "ä¸€èˆ¬"
    else:
        performance = "è¾ƒå·®"
    
    report = f"""
# è¯¯å·®é¢„æµ‹æ¨¡å‹æŠ¥å‘Š

## æ¨¡å‹æ¦‚è¿°
- **æ¨¡å‹ç±»å‹**: Ridgeå›å½’
- **ç‰¹å¾**: KDEå¯†åº¦åŠå…¶å˜æ¢
- **ç›®æ ‡**: é¢„æµ‹MAEè¯¯å·®
- **æ€§èƒ½è¯„ä»·**: {performance}

## æ€§èƒ½æŒ‡æ ‡

### è®­ç»ƒé›†è¡¨ç°
- MAE: {results['train_mae']:.3f}
- RMSE: {results['train_rmse']:.3f}
- RÂ²: {results['train_r2']:.3f}

### æµ‹è¯•é›†è¡¨ç°  
- MAE: {results['test_mae']:.3f}
- RMSE: {results['test_rmse']:.3f}
- RÂ²: {results['test_r2']:.3f}

### äº¤å‰éªŒè¯ç»“æœ
- å¹³å‡MAE: {results['cv_mae']:.3f} Â± {results['cv_std']:.3f}

## æ¨¡å‹é…ç½®
- æ­£åˆ™åŒ–å‚æ•°Î±: {results['alpha']:.4f}
- ç‰¹å¾æ•°é‡: {len(results['feature_names'])}
- æˆªè·: {results['model_intercept']:.4f}

## ç‰¹å¾é‡è¦æ€§åˆ†æ
"""
    
    for i, (feature, importance) in enumerate(feature_importance.items(), 1):
        report += f"{i}. **{feature}**: {importance:.4f}\n"
    
    report += f"""

## æ¨¡å‹è§£é‡Š

### æ€§èƒ½åˆ†æ
{'æ¨¡å‹èƒ½å¤Ÿè¾ƒå¥½åœ°é¢„æµ‹è¯¯å·®ï¼Œå…·æœ‰å®ç”¨ä»·å€¼ã€‚' if test_r2 > 0.3 else 'æ¨¡å‹é¢„æµ‹èƒ½åŠ›æœ‰é™ï¼Œå¯èƒ½éœ€è¦æ›´å¤šç‰¹å¾æˆ–ä¸åŒæ–¹æ³•ã€‚'}

RÂ²ä¸º{test_r2:.3f}ï¼Œè¡¨æ˜æ¨¡å‹èƒ½å¤Ÿè§£é‡Š{test_r2*100:.1f}%çš„è¯¯å·®å˜å¼‚ã€‚

### ç‰¹å¾åˆ†æ
æœ€é‡è¦çš„ç‰¹å¾æ˜¯{list(feature_importance.keys())[0]}ï¼Œè¯´æ˜{'åŸå§‹KDEå¯†åº¦' if list(feature_importance.keys())[0] == 'kde_density' else 'KDEå¯†åº¦çš„å˜æ¢å½¢å¼'}å¯¹è¯¯å·®é¢„æµ‹æœ€æœ‰ç”¨ã€‚

## åº”ç”¨å»ºè®®

1. **é¢„æµ‹ç½®ä¿¡åº¦**: å½“RÂ²>{test_r2:.1f}æ—¶ï¼Œå¯ä»¥è¾ƒä¸ºå¯é åœ°ä½¿ç”¨è¯¥æ¨¡å‹é¢„æµ‹è¯¯å·®
2. **é€‚ç”¨èŒƒå›´**: æ¨¡å‹é€‚ç”¨äºKDEå¯†åº¦åœ¨[{results.get('kde_min', 'N/A'):.6f}, {results.get('kde_max', 'N/A'):.6f}]èŒƒå›´å†…çš„æ ·æœ¬
3. **æ”¹è¿›æ–¹å‘**: {'è€ƒè™‘å¢åŠ æ›´å¤šç‰¹å¾æˆ–ä½¿ç”¨éçº¿æ€§æ¨¡å‹' if test_r2 < 0.5 else 'å½“å‰æ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼Œå¯ç›´æ¥åº”ç”¨'}

## æŠ€æœ¯ç»†èŠ‚
- ç‰¹å¾æ ‡å‡†åŒ–: StandardScaler
- æ­£åˆ™åŒ–: L2 Ridgeå›å½’  
- äº¤å‰éªŒè¯: 5æŠ˜
- è¶…å‚æ•°ä¼˜åŒ–: RidgeCVç½‘æ ¼æœç´¢
"""
    
    return report

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª è¯¯å·®é¢„æµ‹æ¨¡å‹æµ‹è¯•...")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    np.random.seed(42)
    kde_densities = np.random.exponential(0.01, 1000)
    # åˆ›å»ºä¸KDEæœ‰å…³çš„MAEï¼ˆæ¨¡æ‹Ÿè´Ÿç›¸å…³å…³ç³»ï¼‰
    mae_values = 5 + 2 * np.log(1/(kde_densities + 1e-10)) + np.random.normal(0, 1, 1000)
    mae_values = np.abs(mae_values)  # ç¡®ä¿MAEä¸ºæ­£
    
    print("ğŸ“ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•")
    results = run_error_prediction(kde_densities, mae_values)
    
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("ğŸ“ å®é™…ä½¿ç”¨æ—¶è¯·ä¼ å…¥çœŸå®çš„KDEå¯†åº¦å’ŒMAEæ•°æ®") 
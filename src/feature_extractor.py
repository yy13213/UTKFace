#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰¹å¾æå–ä¸å¹´é¾„é¢„æµ‹æ¨¡å—
ä½¿ç”¨é¢„è®­ç»ƒResNet18æå–512ç»´ç‰¹å¾ï¼Œè®­ç»ƒå›å½’å™¨é¢„æµ‹å¹´é¾„å¹¶è®¡ç®—MAE
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.models as models
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import pickle
import os
from typing import Tuple, List, Dict, Optional
from tqdm import tqdm

class FeatureExtractor(nn.Module):
    """ResNet18ç‰¹å¾æå–å™¨"""
    
    def __init__(self):
        super(FeatureExtractor, self).__init__()
        # åŠ è½½é¢„è®­ç»ƒResNet18
        resnet = models.resnet18(pretrained=True)
        # ç§»é™¤æœ€åçš„åˆ†ç±»å±‚ï¼Œä¿ç•™ç‰¹å¾æå–éƒ¨åˆ†
        self.features = nn.Sequential(*list(resnet.children())[:-1])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        
    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)  # è¾“å‡º512ç»´ç‰¹å¾
        return x

class AgeRegressor(nn.Module):
    """ç®€å•çš„å¹´é¾„å›å½’å™¨"""
    
    def __init__(self, input_dim=512):
        super(AgeRegressor, self).__init__()
        self.regressor = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 1)
        )
        
    def forward(self, x):
        return self.regressor(x).squeeze()

class FeatureAgePredictor:
    """ç‰¹å¾æå–ä¸å¹´é¾„é¢„æµ‹çš„å®Œæ•´æµç¨‹"""
    
    def __init__(self, device=None):
        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.feature_extractor = FeatureExtractor().to(self.device)
        self.age_regressor = AgeRegressor().to(self.device)
        
        # å†»ç»“ç‰¹å¾æå–å™¨å‚æ•°
        for param in self.feature_extractor.parameters():
            param.requires_grad = False
        
        print(f"âœ… æ¨¡å‹å·²åˆå§‹åŒ–ï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def extract_features(self, dataloader: DataLoader) -> Tuple[np.ndarray, np.ndarray]:
        """
        æ‰¹é‡æå–ç‰¹å¾
        
        Returns:
            features: (N, 512) ç‰¹å¾çŸ©é˜µ
            ages: (N,) å¹´é¾„æ ‡ç­¾
        """
        self.feature_extractor.eval()
        
        all_features = []
        all_ages = []
        
        print("ğŸ” å¼€å§‹ç‰¹å¾æå–...")
        with torch.no_grad():
            for batch_images, batch_ages, _ in tqdm(dataloader, desc="ç‰¹å¾æå–"):
                batch_images = batch_images.to(self.device)
                
                # æå–ç‰¹å¾
                features = self.feature_extractor(batch_images)
                
                all_features.append(features.cpu().numpy())
                all_ages.extend(batch_ages.numpy())
        
        features = np.vstack(all_features)
        ages = np.array(all_ages)
        
        print(f"âœ… ç‰¹å¾æå–å®Œæˆ: {features.shape[0]}ä¸ªæ ·æœ¬ï¼Œ{features.shape[1]}ç»´ç‰¹å¾")
        return features, ages
    
    def train_age_regressor(self, features: np.ndarray, ages: np.ndarray, 
                           test_size: float = 0.2, epochs: int = 50) -> Dict:
        """
        è®­ç»ƒå¹´é¾„å›å½’å™¨
        
        Returns:
            è®­ç»ƒç»“æœå­—å…¸ï¼ŒåŒ…å«MAEã€RÂ²ç­‰æŒ‡æ ‡
        """
        # æ•°æ®åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            features, ages, test_size=test_size, random_state=42
        )
        
        # è½¬æ¢ä¸ºTensor
        X_train_tensor = torch.FloatTensor(X_train).to(self.device)
        y_train_tensor = torch.FloatTensor(y_train).to(self.device)
        X_test_tensor = torch.FloatTensor(X_test).to(self.device)
        
        # è®­ç»ƒè®¾ç½®
        criterion = nn.MSELoss()
        optimizer = optim.Adam(self.age_regressor.parameters(), lr=0.001)
        
        # è®­ç»ƒå¾ªç¯
        self.age_regressor.train()
        train_losses = []
        
        print(f"ğŸ‹ï¸ å¼€å§‹è®­ç»ƒå¹´é¾„å›å½’å™¨...")
        print(f"   è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        print(f"   æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        
        for epoch in range(epochs):
            optimizer.zero_grad()
            predictions = self.age_regressor(X_train_tensor)
            loss = criterion(predictions, y_train_tensor)
            loss.backward()
            optimizer.step()
            
            train_losses.append(loss.item())
            
            if (epoch + 1) % 10 == 0:
                print(f"   Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}")
        
        # è¯„ä¼°æ¨¡å‹
        self.age_regressor.eval()
        with torch.no_grad():
            train_pred = self.age_regressor(X_train_tensor).cpu().numpy()
            test_pred = self.age_regressor(X_test_tensor).cpu().numpy()
        
        # è®¡ç®—æŒ‡æ ‡
        train_mae = mean_absolute_error(y_train, train_pred)
        test_mae = mean_absolute_error(y_test, test_pred)
        train_r2 = r2_score(y_train, train_pred)
        test_r2 = r2_score(y_test, test_pred)
        
        results = {
            'train_mae': train_mae,
            'test_mae': test_mae,
            'train_r2': train_r2,
            'test_r2': test_r2,
            'train_losses': train_losses,
            'train_predictions': train_pred,
            'test_predictions': test_pred,
            'y_train': y_train,
            'y_test': y_test
        }
        
        print(f"âœ… è®­ç»ƒå®Œæˆï¼")
        print(f"   è®­ç»ƒé›† MAE: {train_mae:.2f}å², RÂ²: {train_r2:.3f}")
        print(f"   æµ‹è¯•é›† MAE: {test_mae:.2f}å², RÂ²: {test_r2:.3f}")
        
        return results
    
    def compute_all_maes(self, features: np.ndarray, ages: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„MAE
        
        Returns:
            mae_values: (N,) æ¯ä¸ªæ ·æœ¬çš„ç»å¯¹è¯¯å·®
        """
        self.age_regressor.eval()
        
        features_tensor = torch.FloatTensor(features).to(self.device)
        
        with torch.no_grad():
            predictions = self.age_regressor(features_tensor).cpu().numpy()
        
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ç»å¯¹è¯¯å·®
        mae_values = np.abs(predictions - ages)
        
        print(f"âœ… MAEè®¡ç®—å®Œæˆï¼Œå¹³å‡MAE: {mae_values.mean():.2f}å²")
        return mae_values
    
    def save_models(self, save_dir: str):
        """ä¿å­˜æ¨¡å‹"""
        os.makedirs(save_dir, exist_ok=True)
        
        torch.save(self.feature_extractor.state_dict(), 
                  os.path.join(save_dir, 'feature_extractor.pth'))
        torch.save(self.age_regressor.state_dict(), 
                  os.path.join(save_dir, 'age_regressor.pth'))
        
        print(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {save_dir}")
    
    def load_models(self, save_dir: str):
        """åŠ è½½æ¨¡å‹"""
        self.feature_extractor.load_state_dict(
            torch.load(os.path.join(save_dir, 'feature_extractor.pth')))
        self.age_regressor.load_state_dict(
            torch.load(os.path.join(save_dir, 'age_regressor.pth')))
        
        print(f"ğŸ“ æ¨¡å‹å·²ä» {save_dir} åŠ è½½")

def plot_training_results(results: Dict, save_path: Optional[str] = None):
    """ç»˜åˆ¶è®­ç»ƒç»“æœ"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('å¹´é¾„é¢„æµ‹æ¨¡å‹è®­ç»ƒç»“æœ', fontsize=16, fontweight='bold')
    
    # è®­ç»ƒæŸå¤±æ›²çº¿
    axes[0, 0].plot(results['train_losses'])
    axes[0, 0].set_title('è®­ç»ƒæŸå¤±æ›²çº¿')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('MSE Loss')
    axes[0, 0].grid(True, alpha=0.3)
    
    # è®­ç»ƒé›†é¢„æµ‹vsçœŸå®
    axes[0, 1].scatter(results['y_train'], results['train_predictions'], alpha=0.5, s=1)
    axes[0, 1].plot([0, 100], [0, 100], 'r--', alpha=0.8)
    axes[0, 1].set_title(f'è®­ç»ƒé›†é¢„æµ‹æ•ˆæœ (MAE: {results["train_mae"]:.2f})')
    axes[0, 1].set_xlabel('çœŸå®å¹´é¾„')
    axes[0, 1].set_ylabel('é¢„æµ‹å¹´é¾„')
    axes[0, 1].grid(True, alpha=0.3)
    
    # æµ‹è¯•é›†é¢„æµ‹vsçœŸå®
    axes[1, 0].scatter(results['y_test'], results['test_predictions'], alpha=0.6, s=1)
    axes[1, 0].plot([0, 100], [0, 100], 'r--', alpha=0.8)
    axes[1, 0].set_title(f'æµ‹è¯•é›†é¢„æµ‹æ•ˆæœ (MAE: {results["test_mae"]:.2f})')
    axes[1, 0].set_xlabel('çœŸå®å¹´é¾„')
    axes[1, 0].set_ylabel('é¢„æµ‹å¹´é¾„')
    axes[1, 0].grid(True, alpha=0.3)
    
    # è¯¯å·®åˆ†å¸ƒ
    train_errors = np.abs(results['y_train'] - results['train_predictions'])
    test_errors = np.abs(results['y_test'] - results['test_predictions'])
    
    axes[1, 1].hist(train_errors, bins=30, alpha=0.5, label='è®­ç»ƒé›†', density=True)
    axes[1, 1].hist(test_errors, bins=30, alpha=0.5, label='æµ‹è¯•é›†', density=True)
    axes[1, 1].set_title('é¢„æµ‹è¯¯å·®åˆ†å¸ƒ')
    axes[1, 1].set_xlabel('ç»å¯¹è¯¯å·® (å²)')
    axes[1, 1].set_ylabel('å¯†åº¦')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š è®­ç»ƒç»“æœå›¾å·²ä¿å­˜åˆ°: {save_path}")
    
    plt.show()

def run_feature_extraction_and_prediction(dataset, batch_size: int = 32) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    è¿è¡Œå®Œæ•´çš„ç‰¹å¾æå–ä¸å¹´é¾„é¢„æµ‹æµç¨‹
    
    Returns:
        features: (N, 512) ç‰¹å¾çŸ©é˜µ
        ages: (N,) å¹´é¾„æ ‡ç­¾  
        mae_values: (N,) æ¯ä¸ªæ ·æœ¬çš„MAE
    """
    from dataset import create_dataloader
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    dataloader = create_dataloader(dataset, batch_size=batch_size, shuffle=False)
    
    # åˆå§‹åŒ–æ¨¡å‹
    predictor = FeatureAgePredictor()
    
    # ç‰¹å¾æå–
    features, ages = predictor.extract_features(dataloader)
    
    # è®­ç»ƒå¹´é¾„å›å½’å™¨
    training_results = predictor.train_age_regressor(features, ages)
    
    # ç»˜åˆ¶è®­ç»ƒç»“æœ
    plot_training_results(training_results, 'results/plots/age_prediction_results.png')
    
    # è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„MAE
    mae_values = predictor.compute_all_maes(features, ages)
    
    # ä¿å­˜æ¨¡å‹
    predictor.save_models('models/')
    
    # ä¿å­˜ç»“æœ
    results_df = pd.DataFrame({
        'age': ages,
        'mae': mae_values
    })
    results_df.to_csv('results/features_and_mae.csv', index=False)
    
    # ä¿å­˜ç‰¹å¾çŸ©é˜µ
    np.save('results/features.npy', features)
    
    print(f"âœ… ä»»åŠ¡4å®Œæˆï¼")
    print(f"   ç‰¹å¾çŸ©é˜µ: {features.shape}")
    print(f"   å¹³å‡MAE: {mae_values.mean():.2f}å²")
    print(f"   ç»“æœå·²ä¿å­˜åˆ°: results/")
    
    return features, ages, mae_values

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª ç‰¹å¾æå–ä¸å¹´é¾„é¢„æµ‹æ¨¡å—æµ‹è¯•...")
    
    # è¿™é‡Œéœ€è¦å®é™…çš„æ•°æ®é›†æ¥æµ‹è¯•
    # test_data_dir = "data/utkface"
    # if os.path.exists(test_data_dir):
    #     from dataset import UTKFaceDataset, get_default_transforms
    #     dataset = UTKFaceDataset(test_data_dir, transform=get_default_transforms())
    #     features, ages, mae_values = run_feature_extraction_and_prediction(dataset)
    # else:
    #     print("âš ï¸  éœ€è¦UTKFaceæ•°æ®é›†æ¥è¿è¡Œæµ‹è¯•")
    
    print("ğŸ“ è¯·ç¡®ä¿æœ‰UTKFaceæ•°æ®é›†åè°ƒç”¨ run_feature_extraction_and_prediction() å‡½æ•°") 